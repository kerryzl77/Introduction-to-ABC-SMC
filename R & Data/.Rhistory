getwd()
# Simulating observed data
set.seed(123)
true_mean <- 5
observed_data <- rnorm(100, mean = true_mean, sd = 1)
# ABC parameters
N <- 1000  # number of accepted particles
epsilon <- 0.1  # constant tolerance level
prior_min <- -10  # U[-10,10] prior
prior_max <- 10
# Distance function
calc_distance <- function(data1, data2) {
abs(mean(data1) - mean(data2))
}
# ABC Rejection Sampling algorithm
res <- matrix(ncol = 2, nrow = N)  # results matrix
colnames(res) <- c("theta", "distance")
i <- 1  # counter for accepted particles
j <- 1  # counter for total proposals
while(i <= N) {
# Sample from the prior
theta_star <- runif(1, prior_min, prior_max)
# Simulate data set from the model
simulated_data <- rnorm(length(observed_data), mean = theta_star, sd = 1)
# Calculate distance
distance <- calc_distance(simulated_data, observed_data)
if(distance <= epsilon) {
# Store results
res[i,] <- c(theta_star, distance)
i <- i + 1  # update accepted particle counter
}
j <- j + 1  # update total proposal counter
cat("Current acceptance rate = ", i / j, "\r")  # print acceptance rate
}
# Save results to CSV file
write.csv(res, "ABC_Rejection_Sampling_Results.csv", row.names = FALSE)
# Simulating observed data
set.seed(123)
true_mean <- 5
observed_data <- rnorm(100, mean = true_mean, sd = 1)
# ABC-SMC parameters
N <- 200  # number of particles
tolerance <- seq(3, 0.1, length.out = 5)  # decreasing tolerance levels
prior_min <- -10  # U[-10,10] prior
prior_max <- 10
# Distance function
calc_distance <- function(data1, data2) {
abs(mean(data1) - mean(data2))
}
# ABC-SMC Algorithm
res <- matrix(ncol = 3, nrow = 0)  # Include weight in the results matrix
colnames(res) <- c("theta", "distance", "weight")
for (epsilon in tolerance) {
accepted_theta <- numeric(0)
accepted_distances <- numeric(0)
weights <- numeric(0)
while (length(accepted_theta) < N) {
# Sampling from the prior
theta <- runif(1, prior_min, prior_max)
# Simulating data from the model
simulated_data <- rnorm(length(observed_data), mean = theta, sd = 1)
# Calculating distance
distance <- calc_distance(simulated_data, observed_data)
# Acceptance condition
if (distance < epsilon) {
accepted_theta <- c(accepted_theta, theta)  # store list of accepted theta under current tolerance
accepted_distances <- c(accepted_distances, distance) # store list of accepted distance under current tolerance
weights <- c(weights, 1 / (distance + .Machine$double.eps))  # inverse of distance as weight
}
}
# Normalize weights
weights <- weights / sum(weights)
# Resampling step: Select indices from accepted particles proportional to weight
resample_indices <- sample(1:N, N, replace = TRUE, prob = weights)
accepted_theta <- accepted_theta[resample_indices]
accepted_distances <- accepted_distances[resample_indices]
weights <- rep(1/N, N)  # Reset uniform weights after resampling
new_entries <- cbind(accepted_theta, accepted_distances, weights)
res <- rbind(res, new_entries)
print(paste("Tolerance:", epsilon, "Mean estimate:", mean(accepted_theta)))
}
# Save results to CSV file for ABC-SMC
write.csv(res, "ABC_SMC_Results.csv", row.names = FALSE)
# Posterior estimate
posterior_estimate <- mean(res[, "theta"])
print(paste("Final posterior mean estimate:", posterior_estimate))
# This file reproduce Figure 3 and 4 in the report. Noted the simulation may varies.
# !!! Remember to run ABC-Rej_Normal.R and ABC-SMC-Normal.R beforehead
# !!! Check the corresponding csv below exsist
abc_rej <- read.csv("ABC_Rejection_Sampling_Results.csv") # 1000 obs * 2 variables
abc_smc <- read.csv("ABC_SMC_Results.csv") # 1000 obs * 3 variables
# Figure 3 in the Report / ABC Distribution.png
par(mfrow=c(1,2))
hist(abc_rej$theta, xlab = expression(mu), main = 'ABC Rejection Sampling')
abline(v = 5, col = 'red', lwd = 2, lty = 'dashed')
hist(abc_smc$theta, xlab = expression(mu), main = 'ABC SMC Sampling')
abline(v = 5, col = 'red', lwd = 2, lty = 'dashed')
set.seed(123)
Population_Data <- read.csv('Population 1801 - 2021.csv')
# Lower bounds for r and K
lm.low <- c(0, max(Population_Data$Population))
# Upper bounds for r and K
lm.upp <- c(0.05, 2 * max(Population_Data$Population))
# Numerical logistic growth equation
logistic_growth <- function(P0, r, K, time_points) {
# P0 is the initial population size
# r is the intrinsic growth rate
# K is the carrying capacity
# time_points is a vector of times at which to simulate the population size
population <- numeric(length(time_points))
population[1] <- P0
for (i in 2:length(time_points)) {
dt <- time_points[i] - time_points[i - 1]
growth <- r * population[i - 1] * (1 - population[i - 1] / K)
population[i] <- population[i - 1] + growth * dt
}
return(population)
}
# Analytic logistic growth equation
# logistic_growth <- function(P0, r, K, time_points) {
#   # P0 is the initial population size
#   # r is the intrinsic growth rate
#   # K is the carrying capacity
#   # time_points is a vector of times starts at 0 for the initial population
#   if (min(time_points) != 0) {
#     time_points <- c(0, time_points)
#   }
#   population <- K / (1 + ((K - P0) / P0) * exp(-r * (time_points - min(time_points))))
#   return(population)
# }
# Distance function
# calc_distance <- function(data1, data2) {
#   abs(mean(data1) - mean(data2))
# }
calc_distance <- function(data1, data2) {
sqrt(mean((data1 - data2)^2))
}
# Observed population data
observed_population <- Population_Data$Population
time_points <- Population_Data$Year
# Initialize Prior
r_prior <- runif(1000, lm.low[1], lm.upp[1])
K_prior <- runif(1000, lm.low[2], lm.upp[2])
N_particles <- 1000
tolerance <- seq(3, 0.1, length.out = 10) # Decreasing tolerance levels
particles <- matrix(nrow = N_particles, ncol = 2) # results matrix
weights <- rep(1/N_particles, N_particles)
# Main Sampling Algorithm
for (g in 1:length(tolerance)) {
epsilon <- tolerance[g]
accepted <- FALSE
attempt <- 1
while (!accepted) {
new_particles <- matrix(nrow = N_particles, ncol = 2)
new_weights <- numeric(N_particles)
# Standard deviations for perturbation
sd_r <- sd(particles[, 1]) / 2
sd_K <- sd(particles[, 2]) / 2
for (i in 1:N_particles) {
if (g > 1 && attempt == 1) {
# Perturbation on particles from the previous generation
index <- sample(1:N_particles, 1, prob = weights)
particles[i, ] <- rnorm(2, mean = particles[index, ], sd = c(sd_r, sd_K))
} else {
# Sample from prior
particles[i, ] <- c(r_prior[i], K_prior[i])
}
# Simulating data from the model
simulated_population <- logistic_growth(P0 = observed_population[1], r = particles[i, 1], K = particles[i, 2], time_points = time_points)
# Calculate distances
distance <- calc_distance(simulated_population, observed_population)
# Calculate weights
if (!is.na(distance) && distance < epsilon) {
new_particles[i, ] <- particles[i, ]    # weight base on inverse of the distance
new_weights[i] <- 1 / (distance + 1e-6) # avoid division by zero
}
}
# Check number of accepted particles greater than zero
if (sum(new_weights) > 0) {
accepted <- TRUE
# Normalize weights
weights <- new_weights / sum(new_weights)
particles <- new_particles
# Calculate Effective Sample Size (ESS)
ESS <- 1 / sum(weights^2)
print(paste("Generation", g, "ESS:", ESS))
# Resample particles based on normalized weights
particles <- particles[sample(1:N_particles, N_particles, replace = TRUE, prob = weights), ]
} else {
# No particles were accepted then resample
attempt <- attempt + 1
if (attempt > 10) {
# If too many attempts, increase tolerance slightly
epsilon <- epsilon * 1.1
}
}
}
# Keep track of Generation & Attempt
print(paste("Generation:", g, "Tolerance:", epsilon, "Attempts:", attempt))
}
posterior_results <- data.frame(
r = particles[, 1],
K = particles[, 2]
)
# Save the posterior results to a CSV file
write.csv(posterior_results, "Population_Results_ABC_SMC.csv", row.names = FALSE)
# Posterior estimate
r_estimate <- sum(particles[, 1] * weights)
K_estimate <- sum(particles[, 2] * weights)
print(paste("Estimated growth rate r:", r_estimate))
print(paste("Estimated carrying capacity K:", K_estimate))
# !!! Remember to run ABC SMC Population.R beforehead
# !!! Check the corresponding csv below exsist
Population_Data <- read.csv('Population 1801 - 2021.csv')
# Define the logistic growth model function
logistic_growth <- function(t, P0, r, K) {
P0 * K / (P0 + (K - P0) * exp(-r * (t - min(t))))
}
# Find nls() best fit for 'r' and 'K from the data
model <- nls(Population ~ logistic_growth(Year, P0, r, K),
data = Population_Data,
start = list(P0 = min(Population_Data$Population),
r = 0.03,
K = max(Population_Data$Population)*1.5))
# Extract estimates for r and K
r_estimate <- coef(model)["r"]
K_estimate <- coef(model)["K"]
abc_smc_population <- read.csv("Population_Results_ABC_SMC.csv")
mean_r <- mean(abc_smc_population$r)
mean_K <- mean(abc_smc_population$K)
# Figure 4 in the Report / Population.png
par(mfrow=c(1,2))
hist(abc_smc_population$r, xlab = expression(r),
xlim=c(mean_r - 1.2 * mean_r, mean_r + 1.2 * mean_r),
main = 'Growth Rate')
abline(v = r_estimate, col = 'red', lwd = 2, lty = 'dashed')
hist(abc_smc_population$K, xlab = expression(K),
xlim=c(mean_K - 1.2 * mean_K, mean_K + 1.2 * mean_K),
main = 'Capacity')
abline(v = K_estimate, col = 'red', lwd = 2, lty = 'dashed')
par(mfrow=c(1,1))
